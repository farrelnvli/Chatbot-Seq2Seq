{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oniC6QFyYZA",
        "outputId": "d932dcd7-ef2e-4fa0-a468-10698061635e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jan  4 22:12:34 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0    53W / 350W |      0MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Zy1vIrzpWb-",
        "outputId": "51fa70cc-fef4-48a6-8e33-bff8caa6f930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 89.6 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkFhF7D5prhJ",
        "outputId": "19adb84a-d2ae-4cd9-b457-a7d92aca2656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow==2.5.0 in /usr/local/lib/python3.8/dist-packages (2.5.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.5.0) (1.19.5)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.5.0) (1.12.1)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.5.0) (2.9.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.5.0) (3.19.6)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.5.0) (2.5.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.5.0) (1.1.2)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.5.0) (1.15.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.5.0) (1.34.1)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.5.0) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.5.0) (3.3.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.5.0) (0.2.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.5.0) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.5.0) (3.7.4.3)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.5.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.5.0) (1.12)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.5.0) (0.38.4)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.5.0) (3.1.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.5.0) (0.15.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.5.0) (0.4.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.25.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (57.4.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0) (5.2.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2022.12.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (3.2.2)\n",
            "2.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.5.0\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jriWC1mNqp3G"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import tensorflow as tf\n",
        "import os\n",
        "import re\n",
        "import tensorflow.keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input, Bidirectional, Concatenate, Dropout, Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sy6l7l3DqsI7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1212f799-acc3-48f3-b613-c53872bf4652"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cpxj5gVKqt-2"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "class AttentionLayer(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # membuat trainable weight\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  \n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
        "\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1) \n",
        "            if verbose:\n",
        "                print('Ua.h>', U_a_dot_h.shape)\n",
        "\n",
        "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', Ws_plus_Uh.shape)\n",
        "\n",
        "\n",
        "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
        "            e_i = K.softmax(e_i)\n",
        " \n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
        "        fake_state_e = K.sum(encoder_out_seq, axis=2)  \n",
        "\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]           "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBFQLHvOqx64"
      },
      "outputs": [],
      "source": [
        "data = pd.read_excel(\"/content/drive/MyDrive/data 13 nov.xlsx\")\n",
        "data.info\n",
        "data\n",
        "\n",
        "raw_ques = data['pertanyaan'].tolist()\n",
        "raw_answ = data['jawaban'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4-xPW9_qzoR"
      },
      "outputs": [],
      "source": [
        "def clean_text(txt):\n",
        "    txt = re.sub(\"[^a-zA-Z]\",\" \",str(txt))\n",
        "    txt = re.sub(r\"i'm\", \"i am\", txt)\n",
        "    txt = re.sub(r\"he's\", \"he is\", txt)\n",
        "    txt = re.sub(r\"she's\", \"she is\", txt)\n",
        "    txt = re.sub(r\"that's\", \"that is\", txt)\n",
        "    txt = re.sub(r\"what's\", \"what is\", txt)\n",
        "    txt = re.sub(r\"where's\", \"where is\", txt)\n",
        "    txt = re.sub(r\"\\'ll\", \" will\", txt)\n",
        "    txt = re.sub(r\"\\'ve\", \" have\", txt)\n",
        "    txt = re.sub(r\"\\'re\", \" are\", txt)\n",
        "    txt = re.sub(r\"\\'d\", \" would\", txt)\n",
        "    txt = re.sub(r\"won't\", \"will not\", txt)\n",
        "    txt = re.sub(r\"can't\", \"can not\", txt)\n",
        "    txt = re.sub(r\"[^\\w\\s]\", \"\", txt)\n",
        "    return txt\n",
        "\n",
        "ques = []\n",
        "answ = []\n",
        "\n",
        "for line in raw_ques:\n",
        "    ques.append(clean_text(line))\n",
        "        \n",
        "for line in raw_answ:\n",
        "    answ.append(clean_text(line))\n",
        "\n",
        "\n",
        "#countword\n",
        "word2count = {}\n",
        "\n",
        "for line in ques:\n",
        "    for word in line.split():\n",
        "        if word not in word2count:\n",
        "            word2count[word] = 1\n",
        "        else:\n",
        "            word2count[word] += 1\n",
        "for line in answ:\n",
        "    for word in line.split():\n",
        "        if word not in word2count:\n",
        "            word2count[word] = 1\n",
        "        else:\n",
        "            word2count[word] += 1\n",
        "\n",
        "#Vocab\n",
        "thresh = 3\n",
        "\n",
        "vocab = {}\n",
        "word_num = 0\n",
        "for word, count in word2count.items():\n",
        "    if count >= thresh:\n",
        "        vocab[word] = word_num\n",
        "        word_num += 1\n",
        "\n",
        "\n",
        "#tokenization\n",
        "for i in range(len(answ)):\n",
        "    answ[i] = '<SOS> ' + answ[i] + ' <EOS>'\n",
        "\n",
        "tokens = ['<PAD>', '<EOS>', '<OUT>', '<SOS>']\n",
        "x = len(vocab)\n",
        "for token in tokens:\n",
        "    vocab[token] = x\n",
        "    x += 1    \n",
        "\n",
        "vocab['can'] = vocab['<PAD>']\n",
        "vocab['<PAD>'] = 0\n",
        "\n",
        "inv_vocab = {w:v for v, w in vocab.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZMXtL7Sq3JQ"
      },
      "outputs": [],
      "source": [
        "encoder_inp = []\n",
        "for line in ques:\n",
        "    lst = []\n",
        "    for word in line.split():\n",
        "        if word not in vocab:\n",
        "            lst.append(vocab['<OUT>'])\n",
        "        else:\n",
        "            lst.append(vocab[word])\n",
        "        \n",
        "    encoder_inp.append(lst)\n",
        "\n",
        "decoder_inp = []\n",
        "for line in answ:\n",
        "    lst = []\n",
        "    for word in line.split():\n",
        "        if word not in vocab:\n",
        "            lst.append(vocab['<OUT>'])\n",
        "        else:\n",
        "            lst.append(vocab[word])        \n",
        "    decoder_inp.append(lst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJlPD7vYq5Ul"
      },
      "outputs": [],
      "source": [
        "encoder_inp = pad_sequences(encoder_inp, 45, padding='post', truncating='post')\n",
        "decoder_inp = pad_sequences(decoder_inp, 45, padding='post', truncating='post')\n",
        "\n",
        "\n",
        "decoder_final_output = []\n",
        "for i in decoder_inp:\n",
        "    decoder_final_output.append(i[1:]) \n",
        "\n",
        "decoder_final_output = pad_sequences(decoder_final_output, 45, padding='post', truncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDfhlzArq7s6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea5daf5f-a773-4782-a433-c658a8f6383e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12560, 45) (12560, 45) (12560, 45) 8075 8074 <PAD>\n"
          ]
        }
      ],
      "source": [
        "VOCAB_SIZE = len(vocab)\n",
        "MAX_LEN = 45\n",
        "\n",
        "print(decoder_final_output.shape, decoder_inp.shape, encoder_inp.shape, len(vocab), len(inv_vocab), inv_vocab[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iiH55Fvq9RM"
      },
      "outputs": [],
      "source": [
        "decoder_final_output = to_categorical(decoder_final_output, len(vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyI1196Lq-4R"
      },
      "outputs": [],
      "source": [
        "embeddings_index = {}\n",
        "with open('/content/drive/MyDrive/glove.6B.50d.txt', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "    f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjFz3OxkrCpq"
      },
      "outputs": [],
      "source": [
        "embedding_dimention = 50\n",
        "def embedding_matrix_creater(embedding_dimention, word_index):\n",
        "    embedding_matrix = np.zeros((len(word_index)+1, embedding_dimention))\n",
        "    for word, i in word_index.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix\n",
        "embedding_matrix = embedding_matrix_creater(50, word_index=vocab) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wU9nYJ1ArEdj"
      },
      "outputs": [],
      "source": [
        "embed = Embedding(VOCAB_SIZE+1, \n",
        "                  50, \n",
        "                  \n",
        "                  input_length=45,\n",
        "                  trainable=True)\n",
        "\n",
        "embed.build((None,))\n",
        "embed.set_weights([embedding_matrix])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6f9sybuprGDV"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "epoch = 50\n",
        "lr = 0.0015\n",
        "latend_dim = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRcDp2ZWrH7a"
      },
      "outputs": [],
      "source": [
        "enc_inp = Input(shape=(45, ))\n",
        "enc_embed = embed(enc_inp)\n",
        "enc_lstm = Bidirectional(LSTM(latend_dim, return_state=True, dropout=0.5, return_sequences = True))\n",
        "encoder_outputs, forward_h, forward_c, backward_h, backward_c = enc_lstm(enc_embed)\n",
        "\n",
        "state_h = Concatenate()([forward_h, backward_h])\n",
        "state_c = Concatenate()([forward_c, backward_c])\n",
        "enc_states = [state_h, state_c]\n",
        "\n",
        "dec_inp = Input(shape=(45, ))\n",
        "dec_embed = embed(dec_inp)\n",
        "dec_lstm = LSTM(latend_dim*2, return_state=True, return_sequences=True, dropout=0.5)\n",
        "decoder_output, _, _,  = dec_lstm(dec_embed, initial_state=enc_states)\n",
        "\n",
        "attn_layer = AttentionLayer()\n",
        "attn_op, attn_state = attn_layer([encoder_outputs, decoder_output])\n",
        "decoder_concat_input = Concatenate(axis=-1)([decoder_output, attn_op])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdkxTKxtrLO1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7afb9e4f-b085-4428-d625-38e5c404f599"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 45)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            [(None, 45)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 45, 50)       403800      input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   [(None, 45, 1024), ( 2306048     embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 1024)         0           bidirectional[0][1]              \n",
            "                                                                 bidirectional[0][3]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 1024)         0           bidirectional[0][2]              \n",
            "                                                                 bidirectional[0][4]              \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 45, 1024), ( 4403200     embedding[1][0]                  \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, 45, 1024), ( 2098176     bidirectional[0][0]              \n",
            "                                                                 lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 45, 2048)     0           lstm_1[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 45, 8075)     16545675    concatenate_2[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 25,756,899\n",
            "Trainable params: 25,756,899\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "dec_dense = Dense(VOCAB_SIZE, activation='softmax')\n",
        "final_output = dec_dense(decoder_concat_input)\n",
        "\n",
        "model = Model([enc_inp, dec_inp], final_output)\n",
        "model.summary()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUXDu3Z4rM3S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88090e1c-2cea-4e40-9350-fd4747003f43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "707/707 [==============================] - 89s 112ms/step - loss: 3.9755 - acc: 0.4055 - val_loss: 3.5989 - val_acc: 0.4213\n",
            "Epoch 2/50\n",
            "707/707 [==============================] - 76s 107ms/step - loss: 3.1444 - acc: 0.4605 - val_loss: 3.2465 - val_acc: 0.4572\n",
            "Epoch 3/50\n",
            "707/707 [==============================] - 76s 108ms/step - loss: 2.6757 - acc: 0.4991 - val_loss: 3.0828 - val_acc: 0.4799\n",
            "Epoch 4/50\n",
            "707/707 [==============================] - 76s 107ms/step - loss: 2.3028 - acc: 0.5397 - val_loss: 3.0113 - val_acc: 0.4947\n",
            "Epoch 5/50\n",
            "707/707 [==============================] - 76s 108ms/step - loss: 2.0019 - acc: 0.5785 - val_loss: 2.9932 - val_acc: 0.5047\n",
            "Epoch 6/50\n",
            "707/707 [==============================] - 77s 108ms/step - loss: 1.7572 - acc: 0.6147 - val_loss: 2.9885 - val_acc: 0.5157\n",
            "Epoch 7/50\n",
            "707/707 [==============================] - 76s 108ms/step - loss: 1.5615 - acc: 0.6464 - val_loss: 3.0079 - val_acc: 0.5216\n",
            "Epoch 8/50\n",
            "707/707 [==============================] - 77s 108ms/step - loss: 1.3975 - acc: 0.6751 - val_loss: 3.0441 - val_acc: 0.5249\n",
            "Epoch 9/50\n",
            "707/707 [==============================] - 76s 108ms/step - loss: 1.2661 - acc: 0.6998 - val_loss: 3.0704 - val_acc: 0.5293\n",
            "Epoch 10/50\n",
            "707/707 [==============================] - 76s 108ms/step - loss: 1.1543 - acc: 0.7215 - val_loss: 3.1163 - val_acc: 0.5315\n",
            "Epoch 11/50\n",
            "707/707 [==============================] - 77s 108ms/step - loss: 1.0578 - acc: 0.7400 - val_loss: 3.1615 - val_acc: 0.5347\n"
          ]
        }
      ],
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
        "history = model.fit([encoder_inp, decoder_inp], decoder_final_output, epochs=epoch, batch_size=batch_size, validation_split=0.1, callbacks=[callback])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['acc']) \n",
        "plt.plot(history.history['val_acc']) \n",
        "plt.title('model accuracy') \n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left') \n",
        "plt.rcParams[\"figure.figsize\"] = (15,8)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vbQ0BCBqC0mR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "a0e9bd52-2c22-4319-a4b4-a4980fc83767"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZO9wmZDhMbJ9"
      },
      "outputs": [],
      "source": [
        "model.save('chatbot.h5')\n",
        "model.save_weights('chatbot_weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrNBMfifMgdh"
      },
      "outputs": [],
      "source": [
        "enc_model = tf.keras.models.Model(enc_inp, [encoder_outputs, enc_states])\n",
        "\n",
        "decoder_state_input_h_f = tf.keras.layers.Input(shape=( latend_dim*2,))\n",
        "decoder_state_input_c_f = tf.keras.layers.Input(shape=( latend_dim*2,))\n",
        "# decoder_state_input_h_b = tf.keras.layers.Input(shape=( latend_dim,))\n",
        "# decoder_state_input_c_b = tf.keras.layers.Input(shape=( latend_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h_f, decoder_state_input_c_f]\n",
        "\n",
        "decoder_outputs, hf, cf = dec_lstm(dec_embed , initial_state=decoder_states_inputs)\n",
        "\n",
        "# h = Concatenate()([hf, hb])\n",
        "# c = Concatenate()([cf, cb])\n",
        "decoder_states = [hf, cf]\n",
        "\n",
        "dec_model = tf.keras.models.Model([dec_inp, decoder_states_inputs],\n",
        "                                      [decoder_outputs] + decoder_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2Iyid5CMhDy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803
        },
        "outputId": "923e3c0e-1542-4347-905a-7275ee3b4b74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "******************************************\n",
            "#       layanan Chatbot COVID-19         #\n",
            "******************************************\n",
            "pengguna : what is covid\n",
            "chatbot menjawab :  early on many of the patients at the epicenter of the covid outbreak in china had some link to a large seafood and live animal market suggesting animal to person spread wuhan city china \n",
            "==============================================\n",
            "pengguna : should i get test\n",
            "chatbot menjawab :  not everyone needs to be tested for covid \n",
            "==============================================\n",
            "pengguna : can my children get covid\n",
            "chatbot menjawab :  Children are being asked to help their children to help their children and family from the community of the virus outbreak \n",
            "==============================================\n",
            "pengguna : how to protect people from covid\n",
            "chatbot menjawab :  Stay away from people who are coughing or sneezing and wash your hands often Maintain at least feet distance between yourself and anyone who is coughing or sniffling \n",
            "==============================================\n",
            "pengguna : should i get vaccine\n",
            "chatbot menjawab :  no currently there is not a vaccine for covid and no specific antiviral medicine to prevent or treat covid \n",
            "==============================================\n",
            "pengguna : can i spread the virus \n",
            "chatbot menjawab :  The main way the disease spreads is transmitted through droplets generated when an infected person coughs sneezes or talks the virus \n",
            "==============================================\n",
            "pengguna : when to use a mask\n",
            "chatbot menjawab :  If you are feeling unwell or have a mask while you are not feeling unwell or if you are not feeling unwell or have a mask \n",
            "==============================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-d7e268d34ff2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mprepro1\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'q'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mprepro1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pengguna : \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprepro1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepro1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "print(\"******************************************\")\n",
        "print(\"#       layanan Chatbot COVID-19         #\")\n",
        "print(\"******************************************\")\n",
        "\n",
        "\n",
        "prepro1 = \"\"\n",
        "while prepro1 != 'q':\n",
        "    \n",
        "    prepro1 = input(\"pengguna : \")\n",
        "    try:\n",
        "        prepro1 = clean_text(prepro1)\n",
        "        prepro = [prepro1]\n",
        "        \n",
        "        txt = []\n",
        "        for x in prepro:\n",
        "            lst = []\n",
        "            for y in x.split():\n",
        "                try:\n",
        "                    lst.append(vocab[y])\n",
        "                except:\n",
        "                    lst.append(vocab['<OUT>'])\n",
        "            txt.append(lst)\n",
        "        txt = pad_sequences(txt, 45, padding='post')\n",
        "\n",
        "        enc_op, stat = enc_model.predict( txt )\n",
        "\n",
        "        empty_target_seq = np.zeros( ( 1 , 1) )\n",
        "        empty_target_seq[0, 0] = vocab['<SOS>']\n",
        "        stop_condition = False\n",
        "        decoded_translation = ''\n",
        "\n",
        "\n",
        "        while not stop_condition :\n",
        "\n",
        "            dec_outputs , hf, cf = dec_model.predict([ empty_target_seq ] + stat )\n",
        "\n",
        "            attn_op, attn_state = attn_layer([enc_op, dec_outputs])\n",
        "            decoder_concat_input = Concatenate(axis=-1)([dec_outputs, attn_op])\n",
        "            decoder_concat_input = dec_dense(decoder_concat_input)\n",
        "\n",
        "            sampled_word_index = np.argmax( decoder_concat_input[0, -1, :] )\n",
        "\n",
        "            sampled_word = inv_vocab[sampled_word_index] + ' '\n",
        "\n",
        "            if sampled_word != '<EOS> ':\n",
        "                decoded_translation += sampled_word           \n",
        "\n",
        "            # if sample_word == '<EOS>' and len(decoded_translation.split()) < 1 :\n",
        "            #     decoded_translation += sampled_word\n",
        "            #     stop_condition = False\n",
        "\n",
        "            if sampled_word == '<EOS> ' or len(decoded_translation.split()) > 45:\n",
        "                stop_condition = True\n",
        "\n",
        "            empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
        "            empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
        "            stat = [hf, cf] \n",
        "\n",
        "        print(\"chatbot menjawab : \", decoded_translation )\n",
        "        print(\"==============================================\")\n",
        "\n",
        "    except:\n",
        "        print(\"maaf kurang dimengerti, coba lagi yaa \")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7-dT46ZM4LZ7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}